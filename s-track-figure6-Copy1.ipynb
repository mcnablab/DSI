{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import dsiadapt as dsi\n",
    "from dipy.viz import fvtk\n",
    "import dipy.core.gradients as grad\n",
    "from dipy.data import get_sphere\n",
    "from dipy.tracking.local import LocalTracking\n",
    "from dipy.viz import fvtk\n",
    "from dipy.viz.colormap import line_colors\n",
    "from dipy.tracking import utils\n",
    "from dipy.tracking.local import ThresholdTissueClassifier\n",
    "from dipy.direction import peaks_from_model\n",
    "\n",
    "%pylab inline\n",
    "np.set_printoptions(threshold=numpy.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ODF sphere directions\n",
    "sphere = get_sphere('symmetric724')\n",
    "# sphere = sphere.subdivide(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112168"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brainmask = nib.load(datapath + '/' + fn + '/' + fn + '_masked_mask.nii.gz').get_data();\n",
    "brainmask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapath = '/data/qytian/QTResearchResult/DSIQspace/DSIData'; # Whole brain data is only locally available \n",
    "qgridsz = 17;\n",
    "\n",
    "fn = 'DSI11_invivo_b7k';\n",
    "data = nib.load(datapath + '/' + fn + '/' + fn + '.nii.gz').get_data();\n",
    "affine = np.identity(4);\n",
    "#affine = nib.load(datapath + '/' + fn + '/' + fn + '.nii.gz').get_affine()\n",
    "brainmask = nib.load(datapath + '/' + fn + '/' + fn + '_masked_mask.nii.gz').get_data();\n",
    "\n",
    "gtab = grad.gradient_table('data/' + fn + '_bvals.txt', 'data/' + fn + '_bvecs_dipy.txt');\n",
    "seedmask = nib.load('data/' + fn + '_roi_mask.nii.gz').get_data();\n",
    "\n",
    "mdd = np.loadtxt('data/' + fn + '_stats.txt')[0];\n",
    "fov = np.loadtxt('data/' + fn + '_stats.txt')[1];\n",
    "\n",
    "winwidth = np.inf;\n",
    "wintype = 'none';  \n",
    "rend = mdd / fov * qgridsz;\n",
    "\n",
    "dsimodel = dsi.DiffusionSpectrumModel(gtab, qgrid_size=qgridsz,\n",
    "            filter_width=winwidth, filter_type=wintype, r_start=0, r_end=rend, r_step=0.2);            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dsipeaks = peaks_from_model(dsimodel, data, sphere,\n",
    "             relative_peak_threshold=.8,\n",
    "             min_separation_angle=45, normalize_peaks=True, mask=brainmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Position (0.00,0.00,1.00)\n",
      "Camera Focal Point (0.00,0.00,0.00)\n",
      "Camera View Up (0.00,1.00,0.00)\n",
      "-------------------------------------\n",
      "Camera New Position (0.00,1.00,0.00)\n",
      "Camera New Focal Point (0.00,0.00,0.00)\n",
      "Camera New View Up (0.00,0.00,1.00)\n"
     ]
    }
   ],
   "source": [
    "classifier = ThresholdTissueClassifier(brainmask, 0.5)\n",
    "\n",
    "seeds = utils.seeds_from_mask(seedmask, density=[2, 2, 2], affine=affine)\n",
    "\n",
    "# Initialization of LocalTracking. The computation happens in the next step.\n",
    "streamlines = LocalTracking(dsipeaks, classifier, seeds, affine, step_size=.5)\n",
    "\n",
    "# Compute streamlines and store as a list.\n",
    "streamlines = list(streamlines)\n",
    "\n",
    "# Prepare the display objects.\n",
    "color = line_colors(streamlines)\n",
    "streamlines_actor = fvtk.line(streamlines, line_colors(streamlines))\n",
    "\n",
    "# Create the 3d display.\n",
    "r = fvtk.ren()\n",
    "fvtk.add(r, streamlines_actor)\n",
    "fvtk.camera(r, pos=(0, 1, 0), viewup=(0, 0, 1))\n",
    "fvtk.show(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utils.seeds_from_mask?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 80, 54)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LocalTracking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fnArr = np.array(['DSI11_invivo_b7k']);\n",
    "affine = hardi_img.get_affine()\n",
    "pdfwgtorderArr = np.array([2]);\n",
    "\n",
    "qgridsz = 129; # Q-space grid size\n",
    "qgridcenter = qgridsz//2;\n",
    "\n",
    "for ii in np.arange(fnArr.shape[0]):\n",
    "    fn = fnArr[ii];\n",
    "    data = nib.load('data/' + fn + '_roi.nii.gz').get_data();\n",
    "    gtab = grad.gradient_table('data/' + fn + '_bvals.txt', 'data/' + fn + '_bvecs_dipy.txt');\n",
    "    mdd = np.loadtxt('data/' + fn + '_stats.txt')[0];\n",
    "    fov = np.loadtxt('data/' + fn + '_stats.txt')[1];\n",
    "\n",
    "    rend = mdd / fov * qgridsz;\n",
    "    dsimodel = dsi.DiffusionSpectrumModel(gtab, qgrid_size=qgridsz, filter_width=np.inf, filter_type='none', r_start=0, r_end=rend, r_step=0.2);\n",
    "    dsifit = dsimodel.fit(data);\n",
    "    odf = dsifit.odf(sphere, pdfwgtorderArr[ii]);\n",
    "\n",
    "    # Save ODF\n",
    "    r = fvtk.ren();\n",
    "    fvtk.add(r, fvtk.sphere_funcs(odf, sphere));\n",
    "    fvtk.camera(r, pos=(0, 1, 0), viewup=(0, 0, 1))\n",
    "    odfname = 'figure5/' + fn + '_roi_odf_wgt_' + str(pdfwgtorderArr[ii]) + '.png';\n",
    "    fvtk.record(r, n_frames=1, out_path=odfname, size=(1600,1000))\n",
    "    #fvtk.show(r)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
