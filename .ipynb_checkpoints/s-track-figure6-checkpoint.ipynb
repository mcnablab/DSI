{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import dsiadapt as dsi\n",
    "from dipy.viz import fvtk\n",
    "import dipy.core.gradients as grad\n",
    "from dipy.data import get_sphere\n",
    "from dipy.tracking.local import LocalTracking\n",
    "from dipy.viz import fvtk\n",
    "from dipy.viz.colormap import line_colors\n",
    "from dipy.tracking import utils\n",
    "from dipy.tracking.local import ThresholdTissueClassifier\n",
    "from dipy.direction import peaks_from_model\n",
    "\n",
    "%pylab inline\n",
    "np.set_printoptions(threshold=numpy.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ODF sphere directions\n",
    "sphere = get_sphere('symmetric724')\n",
    "# sphere = sphere.subdivide(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2.        ,    0.        ,    0.        , -111.38983154],\n",
       "       [   0.        ,    1.96587074,   -0.3679027 ,  -99.08248138],\n",
       "       [   0.        ,    0.36790273,    1.96587074,  -58.87457275],\n",
       "       [   0.        ,    0.        ,    0.        ,    1.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.          -1.5          0.          83.68434143]\n",
      " [  0.           0.           1.5        -72.45481873]\n",
      " [ -1.5          0.           0.          65.8939743 ]\n",
      " [  0.           0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "datapath = '/data/qytian/QTResearchResult/DSIQspace/DSIData'; # Whole brain data is only locally available \n",
    "fnArr = np.array(['DSI11_exvivo']);\n",
    "qgridsz = 65;\n",
    "for ii in np.arange(fnArr.shape[0]):\n",
    "    fn = fnArr[ii];\n",
    "    affine = nib.load(datapath + '/' + fn + '/' + fn + '.nii.gz').get_affine()\n",
    "    disp(affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsipeaks.peak_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "point outside data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-10e5b4e48163>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# Compute streamlines and store as a list.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mstreamlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstreamlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# Prepare the display objects.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/anaconda/lib/python2.7/site-packages/dipy/tracking/utils.pyc\u001b[0m in \u001b[0;36mmove_streamlines\u001b[1;34m(streamlines, output_space, input_space)\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[1;31m# End of initialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstreamlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlin_T\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/anaconda/lib/python2.7/site-packages/dipy/tracking/local/localtracking.pyc\u001b[0m in \u001b[0;36m_generate_streamlines\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseeds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             \u001b[0mdirections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_direction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m             \u001b[0mdirections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdirections\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmax_cross\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfirst_step\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdirections\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mdipy/reconst/peak_direction_getter.pyx\u001b[0m in \u001b[0;36mdipy.reconst.peak_direction_getter.PeaksAndMetricsDirectionGetter.initial_direction (dipy/reconst/peak_direction_getter.c:2618)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: point outside data"
     ]
    }
   ],
   "source": [
    "datapath = '/data/qytian/QTResearchResult/DSIQspace/DSIData'; # Whole brain data is only locally available \n",
    "fnArr = np.array(['DSI11_exvivo']);\n",
    "qgridsz = 65;\n",
    "for ii in np.arange(fnArr.shape[0]):\n",
    "    fn = fnArr[ii];\n",
    "    data = nib.load(datapath + '/' + fn + '/' + fn + '.nii.gz').get_data();\n",
    "    #affine = np.identity(4);\n",
    "    affine = nib.load(datapath + '/' + fn + '/' + fn + '.nii.gz').get_affine()\n",
    "    mask = nib.load(datapath + '/' + fn + '/' + fn + '_masked_mask.nii.gz').get_data();\n",
    "    \n",
    "    gtab = grad.gradient_table('data/' + fn + '_bvals.txt', 'data/' + fn + '_bvecs_dipy.txt');\n",
    "    seedmask = nib.load('data/' + fn + '_roi_mask.nii.gz').get_data();\n",
    "\n",
    "    mdd = np.loadtxt('data/' + fn + '_stats.txt')[0];\n",
    "    fov = np.loadtxt('data/' + fn + '_stats.txt')[1];\n",
    "    \n",
    "    winwidth = np.inf;\n",
    "    wintype = 'none';  \n",
    "    rend = mdd / fov * qgridsz;\n",
    "            \n",
    "    dsimodel = dsi.DiffusionSpectrumModel(gtab, qgrid_size=qgridsz,\n",
    "                filter_width=winwidth, filter_type=wintype, r_start=0, r_end=rend, r_step=0.2);            \n",
    "    \n",
    "    dsipeaks = peaks_from_model(dsimodel, data, sphere,\n",
    "                 relative_peak_threshold=.2,\n",
    "                 min_separation_angle=25, normalize_peaks=True)\n",
    "    \n",
    "    classifier = ThresholdTissueClassifier(mask, 0.5)\n",
    "\n",
    "    seeds = utils.seeds_from_mask(seedmask, density=[2, 2, 2], affine=affine)\n",
    "\n",
    "    # Initialization of LocalTracking. The computation happens in the next step.\n",
    "    streamlines = LocalTracking(dsipeaks, classifier, seeds, affine, step_size=.5)\n",
    "\n",
    "    # Compute streamlines and store as a list.\n",
    "    streamlines = list(streamlines)\n",
    "\n",
    "    # Prepare the display objects.\n",
    "    color = line_colors(streamlines)\n",
    "    streamlines_actor = fvtk.line(streamlines, line_colors(streamlines))\n",
    "\n",
    "    # Create the 3d display.\n",
    "    r = fvtk.ren()\n",
    "    fvtk.add(r, streamlines_actor)\n",
    "    fvtk.show(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utils.seeds_from_mask?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 80, 54)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LocalTracking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fnArr = np.array(['DSI11_invivo_b7k']);\n",
    "affine = hardi_img.get_affine()\n",
    "pdfwgtorderArr = np.array([2]);\n",
    "\n",
    "qgridsz = 129; # Q-space grid size\n",
    "qgridcenter = qgridsz//2;\n",
    "\n",
    "for ii in np.arange(fnArr.shape[0]):\n",
    "    fn = fnArr[ii];\n",
    "    data = nib.load('data/' + fn + '_roi.nii.gz').get_data();\n",
    "    gtab = grad.gradient_table('data/' + fn + '_bvals.txt', 'data/' + fn + '_bvecs_dipy.txt');\n",
    "    mdd = np.loadtxt('data/' + fn + '_stats.txt')[0];\n",
    "    fov = np.loadtxt('data/' + fn + '_stats.txt')[1];\n",
    "\n",
    "    rend = mdd / fov * qgridsz;\n",
    "    dsimodel = dsi.DiffusionSpectrumModel(gtab, qgrid_size=qgridsz, filter_width=np.inf, filter_type='none', r_start=0, r_end=rend, r_step=0.2);\n",
    "    dsifit = dsimodel.fit(data);\n",
    "    odf = dsifit.odf(sphere, pdfwgtorderArr[ii]);\n",
    "\n",
    "    # Save ODF\n",
    "    r = fvtk.ren();\n",
    "    fvtk.add(r, fvtk.sphere_funcs(odf, sphere));\n",
    "    fvtk.camera(r, pos=(0, 1, 0), viewup=(0, 0, 1))\n",
    "    odfname = 'figure5/' + fn + '_roi_odf_wgt_' + str(pdfwgtorderArr[ii]) + '.png';\n",
    "    fvtk.record(r, n_frames=1, out_path=odfname, size=(1600,1000))\n",
    "    #fvtk.show(r)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
